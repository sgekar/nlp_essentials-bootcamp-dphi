{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "wGdpBKaHXuoc"
   },
   "source": [
    "# Sarcasm Detection through NLP and Feature Recognition\n",
    "\n",
    "---\n",
    "In this challenge, you will work on a dataset that contains news headlines - which are aimed to be written in a sarcastic manner by the news author. Our job here is to build our NLP models and predict whether the headline is sarcastic or not. \n",
    "\n",
    "*You must upload a CSV with your predictions on the test data, and also upload a notebook showing all your work.*\n",
    "\n",
    "---\n",
    ". \n",
    "Each record of the dataset consists of two attributes:\n",
    "\n",
    "    is_sarcastic: 1 if the record is sarcastic, otherwise 0. This is the target variable.\n",
    "\n",
    "    headline: this is the headline of the news article\n",
    "\n",
    "Saving Prediction File & Sample Submission:\n",
    "\n",
    "    Make sure your CSV has a column labeled as 'prediction'\n",
    "\n",
    "    Number of rows in CSV should match with number of rows in Test Data given below\n",
    "\n",
    "*The Accuracy score on Test data will be used to evaluate your submission.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2lYDs1RjvRn"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "-U-mW8t5YDFH",
    "outputId": "bf0849c5-079d-44cf-a71a-de310210787a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\peshw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\peshw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_de4c8pjvRr"
   },
   "source": [
    "# Load and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "ctP-qx30YUyC",
    "outputId": "ba2083d4-0322-43bc-b7bb-ee8ee28c7575"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "ctP-qx30YUyC",
    "outputId": "ba2083d4-0322-43bc-b7bb-ee8ee28c7575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function classification_report in module sklearn.metrics._classification:\n",
      "\n",
      "classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
      "    Build a text report showing the main classification metrics.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <classification_report>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array-like of shape (n_labels,), default=None\n",
      "        Optional list of label indices to include in the report.\n",
      "    \n",
      "    target_names : list of str of shape (n_labels,), default=None\n",
      "        Optional display names matching the labels (same order).\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    digits : int, default=2\n",
      "        Number of digits for formatting output floating point values.\n",
      "        When ``output_dict`` is ``True``, this will be ignored and the\n",
      "        returned values will not be rounded.\n",
      "    \n",
      "    output_dict : bool, default=False\n",
      "        If True, return output as dict.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    zero_division : \"warn\", 0 or 1, default=\"warn\"\n",
      "        Sets the value to return when there is a zero division. If set to\n",
      "        \"warn\", this acts as 0, but warnings are also raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    report : str or dict\n",
      "        Text summary of the precision, recall, F1 score for each class.\n",
      "        Dictionary returned if output_dict is True. Dictionary has the\n",
      "        following structure::\n",
      "    \n",
      "            {'label 1': {'precision':0.5,\n",
      "                         'recall':1.0,\n",
      "                         'f1-score':0.67,\n",
      "                         'support':1},\n",
      "             'label 2': { ... },\n",
      "              ...\n",
      "            }\n",
      "    \n",
      "        The reported averages include macro average (averaging the unweighted\n",
      "        mean per label), weighted average (averaging the support-weighted mean\n",
      "        per label), and sample average (only for multilabel classification).\n",
      "        Micro average (averaging the total true positives, false negatives and\n",
      "        false positives) is only shown for multi-label or multi-class\n",
      "        with a subset of classes, because it corresponds to accuracy\n",
      "        otherwise and would be the same for all metrics.\n",
      "        See also :func:`precision_recall_fscore_support` for more details\n",
      "        on averages.\n",
      "    \n",
      "        Note that in binary classification, recall of the positive class\n",
      "        is also known as \"sensitivity\"; recall of the negative class is\n",
      "        \"specificity\".\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    precision_recall_fscore_support, confusion_matrix,\n",
      "    multilabel_confusion_matrix\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import classification_report\n",
      "    >>> y_true = [0, 1, 2, 2, 2]\n",
      "    >>> y_pred = [0, 0, 2, 2, 1]\n",
      "    >>> target_names = ['class 0', 'class 1', 'class 2']\n",
      "    >>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "         class 0       0.50      1.00      0.67         1\n",
      "         class 1       0.00      0.00      0.00         1\n",
      "         class 2       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "        accuracy                           0.60         5\n",
      "       macro avg       0.50      0.56      0.49         5\n",
      "    weighted avg       0.70      0.60      0.61         5\n",
      "    <BLANKLINE>\n",
      "    >>> y_pred = [1, 1, 0]\n",
      "    >>> y_true = [1, 1, 1]\n",
      "    >>> print(classification_report(y_true, y_pred, labels=[1, 2, 3]))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "               1       1.00      0.67      0.80         3\n",
      "               2       0.00      0.00      0.00         0\n",
      "               3       0.00      0.00      0.00         0\n",
      "    <BLANKLINE>\n",
      "       micro avg       1.00      0.67      0.80         3\n",
      "       macro avg       0.33      0.22      0.27         3\n",
      "    weighted avg       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "ctP-qx30YUyC",
    "outputId": "ba2083d4-0322-43bc-b7bb-ee8ee28c7575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44262 entries, 0 to 44261\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   headline      44262 non-null  object\n",
      " 1   is_sarcastic  44262 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 691.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('./data/Train_Data.csv')\n",
    "X_train.info()\n",
    "X_test = pd.read_csv('./data/Test_Data.csv')\n",
    "X_test['is_sarcastic'] = np.float16(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11066 entries, 0 to 11065\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   headline      11066 non-null  object \n",
      " 1   is_sarcastic  11066 non-null  float16\n",
      "dtypes: float16(1), object(1)\n",
      "memory usage: 108.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44262, 2), (11066, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 702
    },
    "colab_type": "code",
    "id": "frQbM_zrZC2D",
    "outputId": "8b46b999-021c-4374-e4e8-255c6a1d73c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  supreme court votes 7-2 to legalize all worldl...             1\n",
       "1  hungover man horrified to learn he made dozens...             1\n",
       "2  emily's list founder: women are the 'problem s...             0\n",
       "3      send your kids back to school with confidence             0\n",
       "4          watch: experts talk pesticides and health             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "X_train['char_count'] = X_train['headline'].apply(len).astype(np.float16)\n",
    "X_train['word_count'] = X_train['headline'].apply(lambda x: len(x.split())).astype(np.float16)\n",
    "X_train['word_density'] = (X_train['char_count'] / (X_train['word_count']+1)).astype(np.float16)\n",
    "X_train['punctuation_count'] = X_train['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) .astype(np.float16)\n",
    "X_train['title_word_count'] = X_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()])).astype(np.float16)\n",
    "X_train['upper_case_word_count'] = X_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()])).astype(np.float16)\n",
    "Y_train = X_train['is_sarcastic']\n",
    "\n",
    "X_test['char_count'] = X_test['headline'].apply(len).astype(np.float16)\n",
    "X_test['word_count'] = X_test['headline'].apply(lambda x: len(x.split())).astype(np.float16)\n",
    "X_test['word_density'] = (X_test['char_count'] / (X_test['word_count']+1)).astype(np.float16)\n",
    "X_test['punctuation_count'] = X_test['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))).astype(np.float16)\n",
    "X_test['title_word_count'] = X_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()])).astype(np.float16)\n",
    "X_test['upper_case_word_count'] = X_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()])).astype(np.float16)\n",
    "Y_test = X_test['is_sarcastic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.300781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.910156</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.855469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>greece seeks to reassure europe as tensions rise</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.332031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44258</th>\n",
       "      <td>vatican says transgender man cannot become a g...</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44259</th>\n",
       "      <td>protesters ejected from donald trump rally aft...</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.667969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44260</th>\n",
       "      <td>italian recipes that are oldies but goodies</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44261</th>\n",
       "      <td>area loser blissfully unaffected by whims of s...</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.699219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44262 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic  \\\n",
       "0      supreme court votes 7-2 to legalize all worldl...             1   \n",
       "1      hungover man horrified to learn he made dozens...             1   \n",
       "2      emily's list founder: women are the 'problem s...             0   \n",
       "3          send your kids back to school with confidence             0   \n",
       "4              watch: experts talk pesticides and health             0   \n",
       "...                                                  ...           ...   \n",
       "44257   greece seeks to reassure europe as tensions rise             0   \n",
       "44258  vatican says transgender man cannot become a g...             0   \n",
       "44259  protesters ejected from donald trump rally aft...             0   \n",
       "44260        italian recipes that are oldies but goodies             0   \n",
       "44261  area loser blissfully unaffected by whims of s...             1   \n",
       "\n",
       "       char_count  word_count  word_density  punctuation_count  \\\n",
       "0            53.0         9.0      5.300781                1.0   \n",
       "1            66.0        12.0      5.078125                0.0   \n",
       "2            65.0        10.0      5.910156                4.0   \n",
       "3            45.0         8.0      5.000000                0.0   \n",
       "4            41.0         6.0      5.855469                1.0   \n",
       "...           ...         ...           ...                ...   \n",
       "44257        48.0         8.0      5.332031                0.0   \n",
       "44258        54.0         8.0      6.000000                0.0   \n",
       "44259        80.0        11.0      6.667969                0.0   \n",
       "44260        43.0         7.0      5.375000                0.0   \n",
       "44261        57.0         9.0      5.699219                0.0   \n",
       "\n",
       "       title_word_count  upper_case_word_count  \n",
       "0                   0.0                    0.0  \n",
       "1                   0.0                    0.0  \n",
       "2                   0.0                    0.0  \n",
       "3                   0.0                    0.0  \n",
       "4                   0.0                    0.0  \n",
       "...                 ...                    ...  \n",
       "44257               0.0                    0.0  \n",
       "44258               0.0                    0.0  \n",
       "44259               0.0                    0.0  \n",
       "44260               0.0                    0.0  \n",
       "44261               0.0                    0.0  \n",
       "\n",
       "[44262 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "44257    0\n",
       "44258    0\n",
       "44259    0\n",
       "44260    0\n",
       "44261    1\n",
       "Name: is_sarcastic, Length: 44262, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wDHsF6qZWNv"
   },
   "source": [
    "# Training a Logistic Regression Model\n",
    "\n",
    "Here we will train a logistic regression model to the feature vectors in training data.\n",
    "\n",
    "\n",
    "Model Evaluation Metrics - Quick Refresher\n",
    "\n",
    "Just accuracy is never enough in datasets with a rare class problem.\n",
    "\n",
    "    Precision: The positive predictive power of a model. Out of all the predictions made by a model for a class, how many are actually correct\n",
    "    Recall: The coverage or hit-rate of a model. Out of all the test data samples belonging to a class, how many was the model able to predict (hit or cover) correctly.\n",
    "    F1-score: The harmonic mean of the precision and recall\n",
    "\n",
    "Do check out ROC Curve, AUC Score and PR Curve also\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     11066\n",
      "\n",
      "    accuracy                           1.00     11066\n",
      "   macro avg       1.00      1.00      1.00     11066\n",
      "weighted avg       1.00      1.00      1.00     11066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  11066"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['headline'], axis=1), Y_train)\n",
    "predictions = lr.predict(X_test.drop(['headline'], axis=1)).astype(np.float16)\n",
    "\n",
    "print(classification_report(Y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "<h2>Features from Sentiment Analysis</h2>\n",
    "\n",
    "Remember this is unsupervised, lexicon-based sentiment analysis where we don't have any pre-labeled data saying which review migth have a positive or negative sentiment. We use the lexicon to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_snt_obj = X_train['headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.300781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.910156</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.855469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>james corden and the red hot chili peppers str...</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.355469</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.379630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u.s. dignity reserves nearly depleted</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.167969</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how to re-ignite the spark in your body, mind ...</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>report: there still time to convert to christi...</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>education reform and evidence</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kid honors grandpa's memory with solemn cannon...</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ragnar from 'vikings' is going where? creator ...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.453125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pope died as he lived: propped up for public v...</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.726562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>documentary about plymouth rock throws in some...</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.667969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jews, muslims, hindus agree on chicken</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.429688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the new new net neutrality</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>white house struggled with asian leaders names...</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.667969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>see chris hemsworth in his 'ghostbusters' uniform</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>should you marry that guy?</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>parents drop fake treating-you-like-an-adult a...</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.667969</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline  is_sarcastic  \\\n",
       "0   supreme court votes 7-2 to legalize all worldl...             1   \n",
       "1   hungover man horrified to learn he made dozens...             1   \n",
       "2   emily's list founder: women are the 'problem s...             0   \n",
       "3       send your kids back to school with confidence             0   \n",
       "4           watch: experts talk pesticides and health             0   \n",
       "5   james corden and the red hot chili peppers str...             0   \n",
       "6               u.s. dignity reserves nearly depleted             1   \n",
       "7   how to re-ignite the spark in your body, mind ...             0   \n",
       "8   report: there still time to convert to christi...             1   \n",
       "9                       education reform and evidence             0   \n",
       "10  kid honors grandpa's memory with solemn cannon...             1   \n",
       "11  ragnar from 'vikings' is going where? creator ...             0   \n",
       "12  pope died as he lived: propped up for public v...             1   \n",
       "13  documentary about plymouth rock throws in some...             1   \n",
       "14             jews, muslims, hindus agree on chicken             1   \n",
       "15                         the new new net neutrality             0   \n",
       "16  white house struggled with asian leaders names...             0   \n",
       "17  see chris hemsworth in his 'ghostbusters' uniform             0   \n",
       "18                         should you marry that guy?             0   \n",
       "19  parents drop fake treating-you-like-an-adult a...             1   \n",
       "\n",
       "    char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         53.0         9.0      5.300781                1.0               0.0   \n",
       "1         66.0        12.0      5.078125                0.0               0.0   \n",
       "2         65.0        10.0      5.910156                4.0               0.0   \n",
       "3         45.0         8.0      5.000000                0.0               0.0   \n",
       "4         41.0         6.0      5.855469                1.0               0.0   \n",
       "5         75.0        13.0      5.355469                2.0               0.0   \n",
       "6         37.0         5.0      6.167969                2.0               0.0   \n",
       "7         54.0        11.0      4.500000                2.0               0.0   \n",
       "8         75.0        11.0      6.250000                1.0               0.0   \n",
       "9         29.0         4.0      5.800781                0.0               0.0   \n",
       "10        50.0         7.0      6.250000                1.0               0.0   \n",
       "11        60.0        10.0      5.453125                3.0               0.0   \n",
       "12        52.0        10.0      4.726562                1.0               0.0   \n",
       "13        85.0        14.0      5.667969                0.0               0.0   \n",
       "14        38.0         6.0      5.429688                2.0               0.0   \n",
       "15        26.0         5.0      4.332031                0.0               0.0   \n",
       "16        68.0        11.0      5.667969                1.0               0.0   \n",
       "17        49.0         7.0      6.125000                2.0               0.0   \n",
       "18        26.0         5.0      4.332031                1.0               0.0   \n",
       "19        69.0         8.0      7.667969                5.0               0.0   \n",
       "\n",
       "    upper_case_word_count  Polarity  Subjectivity  \n",
       "0                     0.0  0.000000      0.000000  \n",
       "1                     0.0  0.000000      0.066667  \n",
       "2                     0.0  0.000000      0.000000  \n",
       "3                     0.0  0.000000      0.000000  \n",
       "4                     0.0  0.000000      0.000000  \n",
       "5                     0.0  0.031481      0.379630  \n",
       "6                     0.0  0.100000      0.400000  \n",
       "7                     0.0  0.000000      0.000000  \n",
       "8                     0.0  0.000000      0.000000  \n",
       "9                     0.0  0.000000      0.000000  \n",
       "10                    0.0  0.000000      0.000000  \n",
       "11                    0.0  0.000000      0.000000  \n",
       "12                    0.0  0.000000      0.066667  \n",
       "13                    0.0  0.125000      0.250000  \n",
       "14                    0.0 -0.600000      0.950000  \n",
       "15                    0.0  0.090909      0.303030  \n",
       "16                    0.0  0.000000      0.000000  \n",
       "17                    0.0  0.000000      0.000000  \n",
       "18                    0.0  0.000000      0.000000  \n",
       "19                    0.0 -0.500000      1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     11066\n",
      "\n",
      "    accuracy                           1.00     11066\n",
      "   macro avg       1.00      1.00      1.00     11066\n",
      "weighted avg       1.00      1.00      1.00     11066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  11066"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['headline'], axis=1), Y_train, )\n",
    "predictions = lr.predict(X_test.drop(['headline'], axis=1)).astype(np.float16)\n",
    "\n",
    "print(classification_report(Y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Text Pre-processing and Wrangling</h2>\n",
    "\n",
    "We want to extract some specific features based on standard NLP feature engineering models like the classic Bag of Words model. For this we need to clean and pre-process our text data. We will build a simple text pre-processor here since the main intent is to look at feature engineering strategies.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "    Text Lowercasing\n",
    "    Removal of contractions\n",
    "    Removing unnecessary characters, numbers and symbols\n",
    "    Stemming\n",
    "    Stopword removal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "#stop_words.remove('no')\n",
    "#stop_words.remove('not')\n",
    "#stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    document = contractions.fix(document)\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.300781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suprem court vote legal worldli vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>hungov man horrifi learn made dozen plan last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.910156</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>emili list founder women problem solver congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>send kid back school confid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.855469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>watch expert talk pesticid health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic  \\\n",
       "0  supreme court votes 7-2 to legalize all worldl...             1   \n",
       "1  hungover man horrified to learn he made dozens...             1   \n",
       "2  emily's list founder: women are the 'problem s...             0   \n",
       "3      send your kids back to school with confidence             0   \n",
       "4          watch: experts talk pesticides and health             0   \n",
       "\n",
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0        53.0         9.0      5.300781                1.0               0.0   \n",
       "1        66.0        12.0      5.078125                0.0               0.0   \n",
       "2        65.0        10.0      5.910156                4.0               0.0   \n",
       "3        45.0         8.0      5.000000                0.0               0.0   \n",
       "4        41.0         6.0      5.855469                1.0               0.0   \n",
       "\n",
       "   upper_case_word_count  Polarity  Subjectivity  \\\n",
       "0                    0.0       0.0      0.000000   \n",
       "1                    0.0       0.0      0.066667   \n",
       "2                    0.0       0.0      0.000000   \n",
       "3                    0.0       0.0      0.000000   \n",
       "4                    0.0       0.0      0.000000   \n",
       "\n",
       "                                      Clean headline  \n",
       "0               suprem court vote legal worldli vice  \n",
       "1  hungov man horrifi learn made dozen plan last ...  \n",
       "2   emili list founder women problem solver congress  \n",
       "3                        send kid back school confid  \n",
       "4                  watch expert talk pesticid health  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Clean headline'] = stp(X_train['headline'].values)\n",
    "X_test['Clean headline'] = stp(X_test['headline'].values)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h2>Extracting out the structured features from previous experiments</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.300781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.910156</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.855469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  char_count  word_count  word_density  punctuation_count  \\\n",
       "0           1.0        53.0         9.0      5.300781                1.0   \n",
       "1           1.0        66.0        12.0      5.078125                0.0   \n",
       "2           0.0        65.0        10.0      5.910156                4.0   \n",
       "3           0.0        45.0         8.0      5.000000                0.0   \n",
       "4           0.0        41.0         6.0      5.855469                1.0   \n",
       "\n",
       "   title_word_count  upper_case_word_count  Polarity  Subjectivity  \n",
       "0               0.0                    0.0       0.0       0.00000  \n",
       "1               0.0                    0.0       0.0       0.06665  \n",
       "2               0.0                    0.0       0.0       0.00000  \n",
       "3               0.0                    0.0       0.0       0.00000  \n",
       "4               0.0                    0.0       0.0       0.00000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_metadata = X_train.drop(['headline', 'Clean headline'], axis=1).reset_index(drop=True).astype(np.float16)\n",
    "X_test_metadata = X_test.drop(['headline', 'Clean headline'], axis=1).reset_index(drop=True).astype(np.float16)\n",
    "\n",
    "X_train_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "\n",
    "<h2>Experiment 3: Adding Bag of Words based Features - 1- and 2-grams</h2>\n",
    "\n",
    "This is perhaps the most simple vector space representational model for unstructured text. A vector space model is simply a mathematical model to represent unstructured text (or any other data) as numeric vectors, such that each dimension of the vector is a specific feature\\attribute.\n",
    "\n",
    "The bag of words model represents each text document as a numeric vector where each dimension is a specific word from the corpus and the value could be its frequency in the document, occurrence (denoted by 1 or 0) or even weighted values.\n",
    "\n",
    "The model’s name is such because each document is represented literally as a ‘bag’ of its own words, disregarding word orders, sequences and grammar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarp</th>\n",
       "      <th>aatish</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abaya</th>\n",
       "      <th>abba</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zookeep</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoroastrian</th>\n",
       "      <th>zsa</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  aaron  aarp  aatish   ab  abandon  abaya  abba  abbey  abbi  ...  zoo  \\\n",
       "0  0.0    0.0   0.0     0.0  0.0      0.0    0.0   0.0    0.0   0.0  ...  0.0   \n",
       "1  0.0    0.0   0.0     0.0  0.0      0.0    0.0   0.0    0.0   0.0  ...  0.0   \n",
       "2  0.0    0.0   0.0     0.0  0.0      0.0    0.0   0.0    0.0   0.0  ...  0.0   \n",
       "3  0.0    0.0   0.0     0.0  0.0      0.0    0.0   0.0    0.0   0.0  ...  0.0   \n",
       "4  0.0    0.0   0.0     0.0  0.0      0.0    0.0   0.0    0.0   0.0  ...  0.0   \n",
       "\n",
       "   zookeep  zooland  zoologist  zoom  zoroastrian  zsa  zucker  zuckerberg  \\\n",
       "0      0.0      0.0        0.0   0.0          0.0  0.0     0.0         0.0   \n",
       "1      0.0      0.0        0.0   0.0          0.0  0.0     0.0         0.0   \n",
       "2      0.0      0.0        0.0   0.0          0.0  0.0     0.0         0.0   \n",
       "3      0.0      0.0        0.0   0.0          0.0  0.0     0.0         0.0   \n",
       "4      0.0      0.0        0.0   0.0          0.0  0.0     0.0         0.0   \n",
       "\n",
       "    zz  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 17117 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
    "X_traincv = cv.fit_transform(X_train['Clean headline']).toarray().astype(np.float16)\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names_out()).astype(np.float16)\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean headline']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names_out()).astype(np.float16)\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aaa</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zookeep</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoroastrian</th>\n",
       "      <th>zsa</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.300781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.910156</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.855469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  char_count  word_count  word_density  punctuation_count  \\\n",
       "0           1.0        53.0         9.0      5.300781                1.0   \n",
       "1           1.0        66.0        12.0      5.078125                0.0   \n",
       "2           0.0        65.0        10.0      5.910156                4.0   \n",
       "3           0.0        45.0         8.0      5.000000                0.0   \n",
       "4           0.0        41.0         6.0      5.855469                1.0   \n",
       "\n",
       "   title_word_count  upper_case_word_count  Polarity  Subjectivity  aaa  ...  \\\n",
       "0               0.0                    0.0       0.0       0.00000  0.0  ...   \n",
       "1               0.0                    0.0       0.0       0.06665  0.0  ...   \n",
       "2               0.0                    0.0       0.0       0.00000  0.0  ...   \n",
       "3               0.0                    0.0       0.0       0.00000  0.0  ...   \n",
       "4               0.0                    0.0       0.0       0.00000  0.0  ...   \n",
       "\n",
       "   zoo  zookeep  zooland  zoologist  zoom  zoroastrian  zsa  zucker  \\\n",
       "0  0.0      0.0      0.0        0.0   0.0          0.0  0.0     0.0   \n",
       "1  0.0      0.0      0.0        0.0   0.0          0.0  0.0     0.0   \n",
       "2  0.0      0.0      0.0        0.0   0.0          0.0  0.0     0.0   \n",
       "3  0.0      0.0      0.0        0.0   0.0          0.0  0.0     0.0   \n",
       "4  0.0      0.0      0.0        0.0   0.0          0.0  0.0     0.0   \n",
       "\n",
       "   zuckerberg   zz  \n",
       "0         0.0  0.0  \n",
       "1         0.0  0.0  \n",
       "2         0.0  0.0  \n",
       "3         0.0  0.0  \n",
       "4         0.0  0.0  \n",
       "\n",
       "[5 rows x 17126 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1).astype(np.float16)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1).astype(np.float16)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     11066\n",
      "\n",
      "    accuracy                           1.00     11066\n",
      "   macro avg       1.00      1.00      1.00     11066\n",
      "weighted avg       1.00      1.00      1.00     11066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  11066"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_comb, Y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "\n",
    "print(classification_report(Y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     1\n",
      "7     0\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    1\n",
      "20    1\n",
      "21    0\n",
      "22    1\n",
      "23    0\n",
      "24    0\n",
      "Name: is_sarcastic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "04-NLP Applications - Text Similarity Content Recommenders.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
